import theano
import theano.tensor as T
import numpy as np


class HiddenLayer:
    """ This is the lth layer in our compositional network. It builds
        phrase of length l by combining sub-phrases of length l-1 and a word.
        This is done in two steps. In the Embed Step, we learn the embedding of
        phrases from l-1 layer and 0 layer(words) that minimizes cross entropy
        between the original and emtimated probability of phrase of length l.

        In second stage, the Compose stage, we learn the compositional operator
        by minimizing reconstruction error between the embedding learning
        in previous step and through composition."""
    def __init__(self,
                 numpy_rng,
                 l=1,
                 L=200,
                 n=50,
                 W_prob=None,
                 b_prob=None,
                 ):

        self.x_l = T.dvector(name='x_l')
        self.x_l_1 = T.dvector(name='x_l_1')
        self.x_1 = T.dvector(name='x_1')

        if W_prob is None:
            initial_W_prob = np.asarray(
                numpy_rng.uniform(
                    low=-4 * np.sqrt(3/n),
                    high=4 * np.sqrt(3/n)),
                size=(n, n),
                dtype=theano.config.floatX),

            W_prob = theano.shared(value=initial_W_prob, name='W_prob', borrow=True)

        if b_prob is None:
            b_prob = theano.shared(value=0.0, name='b_prob', borrow=True)

        self.W_prob = W_prob

        self.b_prob = b_prob

        self.b_l = theano.shared(
            value=np.zeros((n,), dtype=theano.config.floatX),
            name='b_l',
            borrow=True)

        W_l_initial = np.asarray(
            numpy_rng.uniform(
                low=-4*np.sqrt(3/n),
                high=4*np.sqrt(3/n)),
            size=(n, n),
            dtype=theano.config.floatX)

        self.W_l = theano.shared(value=W_l_initial, name='W_l', borrow=True)


